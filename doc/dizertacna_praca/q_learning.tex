\chapter{Q-larning algoritmus}

Q-learning algoritmus je definovaný pre časovo diskrétne systémy.
Agent ktorý prechádza stavový priestor vykonaním niektorej z vopred daných
akcií získava za tieto prechody odmeny. Cieľom algoritmu je ohodnotiť všetky akcie
v jednotlivých stavoch, tak aby bol dosiahnutý ustálený stav a v každom stave
bolo možno vybrať akciu prinášajúcu najväčšiu odmenu, v globálnom zmysle.


\section{Definícia algoritmu}

Daná je množina stavov $\mathbb{S}$ a akcií $\mathbb{A}$, kde
 $\mathbb{S} \in \mathbb{R}^{n_s}$ a $\mathbb{A} \in \mathbb{R}^{n_a}$, kde
$n_s$ a  $n_a$ sú počty prvkov stavového vektora a vektora akcií.

Existuje prechodová funkcia
\begin{align}
        s(n+1) = \lambda(s(n), a(n))
\end{align}

zo stavu $s(n) \in \mathbb{S}$ použitím akcie $a(n) \in \mathbb{A}$, táto funkcia je ale algoritmu neznáma.

Ďalej je daná odmeňovacia funkcia $R(s(n),a(n))$, ktorá vyjadruje okamžité ohodnotenie konania
agenta v $s(n)$ a $a(n)$. V reálnych aplikáciach táto funkcia nadobúda takmer v každom
$s(n)$ a $a(n)$ hodnotu $0$. Pre správnu funkciu algoritmu, musí byť aspoň jedna hodnota
nenulová - napr. ohodnotenie dosiahnutia cieľového stavu (samotná existencia cieľového
stavu však pre algoritmus nie je potrebná).

Funkcia ohodnotení je definovaná ako

\begin{equation}
Q_{n}(s(n),a(n)) = R(s(n),a(n)) + \gamma \max_{a(n-1) \in \mathbb{A}} Q_{n-1}(s(n-1), a(n-1))
\label{eq:q_learning}
\end{equation}

\begin{itemize}
 \item $R(s(n),a(n))$ je odmeňovacia funkcia
 \item $Q_{n-1}(s(n-1),a(n-1))$ je funkcia ohodnotení v stave $s(n-1)$ pre akciu $a(n-1)$
 \item $\gamma$ je odmeňovacia konštanta a platí $\gamma \in (0, 1)$.
\end{itemize}

Funkcia $\ref{eq:q_learning}$ definuje ohodnotenie akcií vo všetkých stavoch t.j.
agent ktorý sa dostal do stavu $s(n)$ vykonaním akcie $a(n)$ zo stavu
$s(n-1)$ získal odmenu $R(s(n),a(n))$ a zlomok najväčšieho možného ohodnotenia ktoré
mohol získať dostaním sa do stavu $s(n-1)$, situáciu ilustruje obrázok \ref{img:q_learning}.


\begin{figure}[!htb]
\center
\includegraphics[scale=.6]{../diagrams/q_learning_detail.eps}
\caption{Ilustrácia funkcie ohodnotení, pre $\gamma = 0.9$}
\label{img:q_learning}
\end{figure}

Nasledujúce obrázky ilustrujú beh algoritmu pre systém so 6 stavmi pre $\gamma = 0.8$.
Na začiatku nie sú známe ani samotné prechody medzi stavmi (Obr. $\ref{img:q_learning_1}$), bol definovaný
1 cieľový stav $S5$, agent začína v stave $S0$ (môže však v ľubovolnom inom).
Ďalej sa pre jednoduchosť predpokladá že

\begin{equation}
R(s(n), a(n)) =
\left\{
	\begin{array}{ll}
		1  & ak \ s(n) = $S5$ \\
    -0.5  & ak \ s(n) = $S4$ \ \wedge \ $a(n) = Ay$  \\
		0 & inak
	\end{array}
\right.
\label{eq:r_func_simple}
\end{equation}

t.j. odmeňovacia funkcia nadobúda hodnotu $1$ len ak sa agent dostal do stavu
$S5$ a pre ilustráciu je definovaná aj jedna záporná odmena pri prechode z $S4$ do
$S3$ akciou $Ay$.

\begin{figure}[!htb]
\center
\includegraphics[scale=.6]{../diagrams/q_learning_table_01.eps}
\caption{Inicializácia}
\label{img:q_learning_1}
\end{figure}

Agent v každom stave náhodne vyberá akcie (na výbere nezáleží, dôležité je aby
každá akcia mala nenulovú pravdepodobnoť výberu, a rovnako bola nenulová
prevdepodobnosť dosiahnutia ľubovolného stavu). Obrázky Obr. \ref{img:q_learning_2}
a Obr. \ref{img:q_learning_3} ilustrujú jednu z možných ciest.


\begin{figure}[!htb]
\center
\includegraphics[scale=.6]{../diagrams/q_learning_table_02.eps}
\caption{Prechod do stavu S1}
\label{img:q_learning_2}
\end{figure}

\begin{figure}[!htb]
\center
\includegraphics[scale=.6]{../diagrams/q_learning_table_03.eps}
\caption{Prechod do stavu S2}
\label{img:q_learning_3}
\end{figure}

Po dosiahnutí cieľového stavu Obr. \ref{img:q_learning_4} je na základe \ref{eq:r_func_simple}
možné spočítať podľa \ref{eq:q_learning} ohodnotenia doteraz vykonaných akcií -
agent získal nenulovú odmenu $R(s_5, a_x) = 1$ (kde $a_x$ značí ľubovolnú akciu),
ktorú rekurentne spočíta pre všetky doteraz vykonané akcie.

Pre zjednodušenú variantu \ref{eq:q_learning} by bolo možné pamätať si len jeden
predošlý stav a nepostupovať v ohodnocovaní rekuretne. V praktickej aplikácií
je potrebné obmedziť hĺbku rekurzie, a pamätať si len posledných $P$ stavov a vnich
urobených rozhodnutiach. V tomto jedńoduchom príklade však nie sú nutné tieto obmedzenia, je teda
možné pamätať si celú cestu.

\begin{figure}[!htb]
\center
\includegraphics[scale=.6]{../diagrams/q_learning_table_04.eps}
\caption{Prechod do stavu S3}
\label{img:q_learning_4}
\end{figure}

Agent môže pokračovať v ceste ďalej, napr. späť \ref{img:q_learning_5} a pribežne
počítať ohodnotenia. Prechod z $s_5$ do $s_2$ je ohodnotený ako $0.8$ - vybralo sa najlepšie
možné ohodnotenie ako sa dostať do $s_5$ ($1$) násobené $\gamma$, $R(s_2, a_x) = 0$
(podľa \ref{eq:r_func_simple}).


\begin{figure}[!htb]
\center
\includegraphics[scale=.6]{../diagrams/q_learning_table_05.eps}
\caption{Ďalšie prechody agenta}
\label{img:q_learning_5}
\end{figure}

Po prejdení celého grafu, kedy agent vykonal všetky možné akcie dosiahne
funkcia $Q(s(n), a(n))$ konečný, ustálený stav Obr. \ref{img:q_learning_6}, teda

\begin{equation}
\forall s(n),\ \forall a(n),\forall \epsilon > 0 \  \exists Q_{n} : \mid Q_{n}(s(n), a(n)) - Q_{n-1}(s(n), a(n)) \mid < \epsilon
\label{eq:q_learning_finish}
\end{equation}

hodnoty Q-funkcie sa teda pri pevne danom $R(s(a), a(n))$ už nemenia.


\begin{figure}[!htb]
\center
\includegraphics[scale=.6]{../diagrams/q_learning_table_06.eps}
\caption{Konečný stav}
\label{img:q_learning_6}
\end{figure}


\section{Výber akcie}

Pre nájdenie konečných hodnôt funkcie ohodnotení podľa \ref{eq:q_learning_finish}
stačí aby každý prechod mal nenulovú pravdepodobnosť vykonania. Pre ďalšie vyšetrovanie
konania agenta ja daná pravdepodobnosť výberu akcie  ako

\begin{equation}
P(s(n), a(s)) = \frac{e^{kQ(s(n), a(s))}}{ \sum\limits_{i=1}^{C_a}{e^{kQ(s(n), a(i))}} }
\label{eq:action_selection}
\end{equation}

kde \\
$s$ je zvolená akcia \\
$C_a$ je počet akcií \\
$k$ je konštanta a platí $k \geq 0$

agent ktorý vyberá všetky akcie s rovnakou pravdepodobnosťou má teda $k = 0$.
Pre vysoké hodnoty $k$ : $\lim_{k\to\infty}$ bude agent vyberať len najlepšie
dostupné akcie. Pre učenie agenta je teda vhodné zvoliť malé $k$.

Je možné definovať ľubovolné iné možnosti výberu akcie, napr. uprednostňovať menej
často vykonané akcie, prípadne podľa zmeny
$\mid Q_{n}(s(n), a(n)) - Q_{n-1}(s(n), a(n)) \mid$ uprednostňovať prechody s veľkou hodnotou zmeny.


\section{Problémy výpočtu $Q(s, a)$}

Algoritmus je definovaný pre diskrétnu množinu stavov. Ďalej sa predpokladá, že
$s(n) \in \langle -1, 1 \rangle$ a podobne $a(n) \in \langle -1, 1 \rangle$

 Pre počty prvkov
stavového vektora a vektora akcií ($n_s$, $n_a$) je možné definovať
delenie ich hodnôt na diskrétny počet $d_s$ a $d_a$, potom je možné vyjadriť celkový počet
hodnôt $Q(s(n), a(n))$ ako

\begin{equation}
C = {d_s}^{n_s} {d_a}^{n_a}
\label{eq:q_size}
\end{equation}

Samotný počet hodnôt ktoré treba spočítať teda exponenciálne narastná z rastom
počtu prvkov stvového a vektora akcií.

Pre úlohy kde do systému vstupuje mnoho nezávislých vstupov sa stáva implentácia Q(s(n), a(n))
problémom najmä z dôvodov :

\begin{itemize}
\item veľké pamäťové nároky
\item o nenavštívených prechodoch nevie agent povedať nič
\end{itemize}

Vhodným riešením sa ukazuje aproximácia Q-funkcie.
Nech je aproximovaná funkcia označená $Q_n'(s(n), a(n))$ a presné riešenie ako $Q_n(s(n), a(n))$.

Dané sú postuláty o tejto aproximácií
\begin{theorem}{Neobmedzená prenosť aproximácie : }
\label{post:01}
Pre všetky stavy $s(n)$ a akcie $a(n)$ musí platiť
$\mid Q_n(s(n), a(n)) - Q_n'(s(n), a(n)) \mid < \epsilon $. Kde $\epsilon > 0$ a
určuje kvalitu aproximácie. Zlepšením vlastností $Q_n'(s(n), a(n))$ je možné
ľubovolne zmenšovať  $\epsilon$.
\end{theorem}

\begin{theorem}{Lokálna zmena : }
\label{post:02}
Lokálna zmena hodnoty $\delta = \mid Q_n'(s(n), a(n)) - Q_{n-1}'(s(n), a(n)) \mid$ neovplyvní hodnotu funkcie v
inom bode o viac ako $\forall \ s(n') \ \forall a(n'),\ n \neq n' : \delta < \kappa$.
Zmenšovaním hdonoty $\kappa$ sa funkcia stáva menej závislá na okolí bodu $[s(n), a(n)]$.
\end{theorem}

Funkciu $Q(s(n), a(n))$ je možné aproximovať niekoľkými spôsobmi.
Tie najbežnejšie sú

\begin{itemize}
\item tabuľka
\item neurónová sieť
  \begin{itemize}
    \item dopredná neurónová sieť
    \item kohonenova mapa
    \item neurónová sieť bázickych funkcií
  \end{itemize}
\end{itemize}

\section{Tabuľka}

Dané sú celočíselné indexy

\begin{align}
  I_s(n) = \lceil \sum\limits_{i=1}^{n_s} {\left( d_s\frac{s_i(n) + 1}{2} \right)^i \rceil}  \\
  I_a(n) = \lceil \sum\limits_{i=1}^{n_a} {\left( d_a\frac{a_i(n) + 1}{2} \right)^i \rceil}
\end{align}

kde \\
$I_s(n)$ je index stavu \\
$I_a(n)$ je index akcie \\
$s_i(n)$ je i-ty prvok vektora stavu $s(n)$ \\
$a_i(n)$ je i-ty prvok vektora akcií $a(n)$ \\

Pre diskrétny počet stavov a akcií je možné definovať tabuľkovú interpretáciu ako
$Q^t(I_s(n), I_a(n))$.
Pre $\lim_{d_s\to\infty}$ a $\lim_{d_a\to\infty}$ je možné považovať tabuľku za presné riešenie
pretože spĺňa postuláty \ref{post:01} aj \ref{post:02}.

\section{Dopredná neurónová sieť}

Pre aproximáciu funkcie ohdnotení je možné použiť dobrednú neurónovú sieť ako
univerzálny aproximátor.

Je daný vstupný vektor

\begin{align}
I(n) = (s(n), a(n))
\label{eq:nn_input_vector}
\end{align}

výstupná hodnota neurónovej siete ako $y_{nn}(n)$ a požadovaná hodnota ako $y_{r}(n)$.

Ďalej je definovaná chyba ako

\begin{align}
e(n) = y_{r}(n) - y_{nn}(n)
\label{eq:nn_error}
\end{align}

Vrstva $l$ doprednej siete je definovaná ako
\begin{align}
y^l(n) &= f^l\left(W^l(n)I^l(n)\right) \nonumber \\
 &= f^l\left(
 \begin{pmatrix}
  w^l_{1,1}(n) & w^l_{1,2}(n) & \cdots & w^l_{1,n'}(n) \\
  w^l_{2,1}(n) & w^l_{2,2}(n) & \cdots & w^l_{2,n'}(n) \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  w^l_{m',1}(n)  & w^l_{m',2}(n)  & \cdots & w^l_{m',n'}(n)
 \end{pmatrix}
 \begin{pmatrix}
  i^l_{1,1}(n) & i^l_{1,2}(n) & \cdots & i^l_{1,n'}(n) \\
 \end{pmatrix}
 \right)
 \label{eq:nn_layer}
\end{align}

kde \\
$n'$ je počet prvkov vstupného vektora \\
$m'$ je počet prvkov výstupného vektora \\
$f(X)$ je aktivačná funkcia \\
$W^l(n)$ je matica váh.

Najčastejšie používané aktivačné funkcie sú sigmoida, hyberbolický tangens , lineárna,
usmerňovač a skoková funkcia. Ich predpisy sú

\begin{align}
y_1(x) &= \frac{1}{1+e^{-x}} \\
y_2(x) &= \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} \\
y_3(x) &= x \\
y_3(x) &= \left\{
	\begin{array}{ll}
		x  & ak \ x > 0 \\
		0 & inak
	\end{array}
\right. \\
y_4(x) &= \left\{
	\begin{array}{ll}
		1  & ak \ x > 0 \\
		-1 & inak
	\end{array}
\right.
\label{eq:nn_transfer_function}
\end{align}

Ich priebehy sú znázornené na obrázku Obr. \ref{img:nn_functions}.

\begin{figure}[!htb]
\center
\includegraphics[scale=.4]{../pictures/nn_functions.png}
\caption{Grafické znázornenie priebehov aktivačných funkcií}
\label{img:nn_functions}
\end{figure}

Zoradením niekoľkých vrstiev za sebou, tak že výstup predošlej je vstupom do aktuálnej
vrstvy je možné získať doprednú neurónovu sieť. Takáto sieť je vhodná na riešenie klasifikačných
aj aproximačných problémov.

Najväčším nedostatkom je mechanizmus učenia.

Existuje niekoľko spôsobov ako túto sieť učiť, najčastejšie sú

\begin{itemize}
\item gradientová metóda minimalizácie chyby
\item simulované žíhanie
\end{itemize}

Gradientová metóda nemá zaručené dosiahnutie globálneho minima pre všeobecné prípady,
simulované žíhanie je časovo náročné pre veľký počet váhových parametrov.

Dopredná sieť je známa nelokálnosťou učenia : pri trénovaní na podmnožinu množiny
požadovaných výstupov sa mení hodnota aj mimo túto podnmožinu. Sieť teda veľmi
problematicky spĺňa postutlát \ref{post:02}. Dobre však spĺňa postulát \ref{post:01},
vhodnou voľbou počtu vrstiev a počtu neurónov je možné dosiahnúť ľubovolnú
presnosť aproximácie.

\section{Kohonenová neurónová sieť}

Pre aproximáciu môže byť použitá Kohonenová neurónová sieť. Každému neurónu
tejto siete je priradená jedna hodnota.

Najpr sa spočítajú vzdialenosti od vstupného vektora

\begin{align}
d_j(n) = \sum\limits_{i=1}^{N}{(I_i(n) - w_{ji}(n))^2}
\label{eq:knn_distance}
\end{align}

kde $w(n) \in \mathbb{R}$ je matica váh, na začiatku sa volí náhodná.
Víťazný neurón $v$ je definovaný ako

\begin{align}
v : \forall j : d_v(n) \leq d_j(n)
\label{eq:knn_winning}
\end{align}

A pre každý neurón existuje priradená výstupná hodnota $y_j(n) \in \mathbb{R}$, výstupom
siete je hodnota priradená výťaznému neurónu $y_{nn}(n) = y_v(n)$

Učenie siete prebieha v dvoch krokoch

1) zmena váh $w(n)$ - zmenia sa váhy výťazného neurónu, pretože najlepšie
zopovedajú požadovaným váham

\begin{align}
w_{ji}(n+1) = (1-\eta_1(j))w_{ji}(n) + \eta_1 I_i(n)
\label{eq:knn_w_update}
\end{align}

kde $\eta_1(j) \in (0, 1)$ je krok učenia a závisí od polohy neurónu v sieti.
V najjednoduhšom prípade

\begin{equation}
\eta_1(j) =
\left\{
	\begin{array}{ll}
		\eta  & ak \ j = v \\
		0 & inak
	\end{array}
\right.
\label{eq:knn_func_simple1}
\end{equation}

k zmene váh teda dôjde len pri víťaznom neuróne.
Ďalší často používaný tvar funkcie postupne zmenšuje hodnotu $\eta_1(j)$ podľa
$d_j(n)$ a to ako

\begin{align}
\eta_1(j, n) = \eta e^{-kd_j(n)}
\label{eq:knn_func_simple2}
\end{align}

kde $k \in (0, \infty )$. Krok učenia $\eta_1(j, n)$ je teda premenný a záleží
aj od predloženého vzoru podľa $n$.

Po dostatočnom počte iterácií sa hodnoty váh ustália na hodnotách tak aby rozdelili
množinu vstupných vektorov na lokálne oblasti. Tento stav je znázornený na Obr. \ref{img:knn_learning_result}.
Vstupný proces generoval 8 zhlukov dát ktoré sieť klasifikovala použitím 16 neurónov.
Každému neurónu je možne priradiť požadovanú hodnotu výstupu.

2) upraví sa výstupná hodnota $y_v(n)$

\begin{align}
y_v(n+1) = y_v(n) + \eta_2 e(n)
\label{eq:knn_y_update}
\end{align}

kde $e(n)$ je chyba podľa \ref{eq:nn_error}.

\begin{figure}[]
\center
\includegraphics[scale=.4]{../pictures/knn_learing_result.png}
\caption{Znázornenie váhových parametrov w pre dvojrozmerný priestor}
\label{img:knn_learning_result}
\end{figure}


\section{Neurónová sieť bázickych funkcií}

Dané sú bázické funkcie $f_j^x(\boldmath{s(n), a(n)})$, kde $x$ je typ bázickej funkcie.
Požadovaná hodnota $Q^x(s(n), a(n))$ je potom lineárnou kombináciou týchto funkcií typu $x$.

Z charakteru Q-learning algoritmu \ref{eq:q_learning} je možné určiť požiadavky na
tieto funkcie :

\begin{enumerate}
\item predpis \ref{eq:q_learning} je tvorený klesajúcou exponenciálou - podobný charakter by mala mať aj bázická funkcia
\item existencia jedného globálneho maxima a zmenou parametrov určovať polohu tohto bodu
\item možnosť ľubovolne meniť strmosť funkcie v okolí maxima
\item funkcia by mala byť zhora aj z dola ohraničená
\end{enumerate}

Cieľom je mať možnosť nezávisle nastaviť maximá funkcií do oblastí, ktoré zodpovedajú
nenulovím hodnotám $R(s(n), a(n))$ - bod 2. Ak ohodnotenie spĺňa podmienku najlepšej
možnej akcie v danom stave, dá sa očakávať že bude mať menšiu strmosť, naopak, ak funkcia
popisuje bod kde $R(s(n), a(n))$ dosahuje malé hodnoty (obvykle záporné), bude požadovaná
vysoká strmosť tejto funkcie - obe požiadavky sú zhrnuté v bode 3. Bod 4 umožňuje rozumne
ohraničiť rozsah funkcie.

Niektoré tvary bázických funkcií
\begin{align}
    f_j^1(\boldmath{s(n), a(n)}) &= e^{ -\sum\limits_{i=1}^{n_s}{\beta_{aji}(n)(s_i(n) - \alpha_{aji}(n))^2} }  \\
    f_j^2(\boldmath{s(n), a(n)}) &= \frac{1}{1 + \sum\limits_{i=1}^{n_s}{\beta_{aji}(n)(s_i(n) - \alpha_{aji}(n))^2}}  \\
    f_j^3(\boldmath{s(n), a(n)}) &= e^{ -\sum\limits_{i=1}^{n_s}{\beta_{aji}(n)\mid s_i(n) - \alpha_{aji}(n) \mid} }
\end{align}

kde \\
$\alpha_{aji}(n) \in \langle -1, 1 \rangle$ určuje polohu maxima funkcie \\
$\beta_{aji}(n) \in (0, \infty)$ určuje strmosť funkcie.

Pre symetrické prechody medzi stavmi ich možno zjednodušiť na

\begin{align}
f_j^1(\boldmath{s(n), a(n)}) &= e^{ -\beta_{aj} \sum\limits_{i=1}^{n_s}{(s_i(n) - \alpha_{aji})^2} }  \\
f_j^2(\boldmath{s(n), a(n)}) &= \frac{1}{1 + {\beta_{aj} \sum\limits_{i=1}^{n_s}(s_i(n) - \alpha_{aji})^2}}  \\
f_j^3(\boldmath{(n)s, a(n)}) &= e^{ -\beta_{aj} \sum\limits_{i=1}^{n_s}{\mid s_i(n) - \alpha_{aji}(n) \mid} }
\label{eq:basis_functions}
\end{align}

Aproximovaná funkcia ohodnotení pre $l$ bázických funkcií je potom

\begin{align}
Q^x(s(n), a(n)) = \sum\limits_{j=1}^{l} w(n)_j^x f_j^x(\boldmath{s(n), a(n)})
\label{eq:knn_y_update}
\end{align}

kde $w(n)_j^x$ sú váhy bázických funkcií.


Je teda potrebné stanoviť celkovo 3 sady parametrov : $\alpha$ $\beta$ $w$.

\subsection{Určenie parametrov $\alpha$}

Parameter $\alpha$ určuje posunutie maxima funkcie a postupuje sa podobne
ako v prípade \ref{eq:knn_w_update}. Treba zohľadniť fakt, že pre konečný
výsledok je dôležité pokryť všetky oblasti s nenulovým $R(s(n),a(n))$, vrchol
krivky bude ležať nad nad bodom $[s(n),a(n)]$.

Zmena parametrov $\alpha$ prebieha v piatich krokoch.

\begin{itemize}
  \item na začiatku sa zvolia $\alpha_{jia}(n)$ náhodne, ze $\langle -1, 1 \rangle$
  \item spočítajú sa vzdialenosti od predloženého vstupu $d_{ja}(n) = \mid s(n) - \alpha_{ja}(n) \mid$
  \item nájde sa také $ka$ kde pre $\forall{j} : d_{ka}(n) \leq d_{ja}(n)$
  \item spočíta sa krok učenia $\eta'_a(n) = \eta_1 \mid Q_r(s(n), a(n)) \mid$
  \item upravia sa parametre $\alpha_{aki}(n+1) = (1 - \eta')\alpha_{aki}(n) + \eta' s_{i}(n)$
\end{itemize}
kde \\
$Q_r(s(n), a(n))$ je požadovaný výstup \\
$\eta_1$ je konštanta učenia

Krok učenia teda závisí od veľkosti požadovanej hodnoty, tým sa zabezpečí aby maximum
krivky naozaj ležalo nad bodom $[s(n),a(n)]$.

\subsection{Určenie parametrov $\beta$}

Parameter $\beta$ určuje strmosť krivky. Ak boli k dizpozicií naraz všetky
požadované výstupy, bolo by možné spočítat tento parameter z rozptylu.
Požadované hodnoty však prichádzajú postupne, strmosť krivky sa preto upravuje preibežne,
podľa toho či požadovaná hodnota leží nad, alebo pod krivkou.

\begin{itemize}
\item stanoví sa chyba $e(n) = Q_r(s(n), a(n)) - Q(s(n), a(n))$
\item pre každú bázickú funkciu  $\beta_{ja}(n+1)= \beta_{ja}(n) + \eta_2 e(n)w_{ja}(n)$
\item skontroluje sa $\beta_{ja}(n) \in (0, \infty)$
\end{itemize}

kde \\
$Q_r(s(n), a(n))$ je požadovaný výstup \\
$\eta_2$ je konštanta učenia \\


\subsection{Určenie váhových parametrov $w$}

Nakoniec sa gradientovou metódou určia váhové paramete. Pre presné
riešenie by bolo možné použiť metódu nejmenších štvorcov, tá je však pre veľký počet
bázcikých funkcií ťažko vypočítateľná. Zmena parametrov je potom daná nasledujúcim postupom

\begin{itemize}
\item stanoví sa chyba $e(n) = Q_r(s(n), a(n)) - Q(s(n), a(n))$
\item pre každé $w_{ja}$ : $w_{ja}(n+1)= w_{ja}(n) + \eta_3 e(n)y_j(n)$
\item skontroluje sa $w_{ja}(n) \in (-r, r)$
\end{itemize}

kde \\
$\eta_3$ je konštanta učenia \\
$r$ je maximálny rozsah váh \\



\newpage

\begin{equation}
H_j(s(n)) =
\left\{
	\begin{array}{ll}
		r_j  & if \ s(n) = \alpha_j \\
		0 & inak
	\end{array}
\right.
\end{equation}

\begin{align}
  f_j(s(n)) = H_j(s(n)) + w_j e^{ -\sum\limits_{i=1}^{n_s}{\beta_{ji}(s_i(n) - \alpha_{ji})^2} }
\end{align}

\begin{align}
  Q(s(n)) = \sum\limits_{j=1}^{J} f_j(s(n))
\end{align}

kde \\
$\alpha_j$ je stav pre ktorý sa počíta funkcia \\
$r_j$ je hodnota okamžitej odmeny $R(s(n))$ v tomto stave \\
$\beta_j$ je strmosť, a platí $\beta > 0$ \\
$w_j$ je váha \\
